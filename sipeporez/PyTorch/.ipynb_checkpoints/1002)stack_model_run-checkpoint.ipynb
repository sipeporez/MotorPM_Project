{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "002798bc-da34-40c5-998d-dc737ef47b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from itertools import chain\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "# import transform_fns as trans\n",
    "import pdm_functions as fns\n",
    "import tensor_vstack as pfns\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bae789f6-40e0-4416-afc4-cab991c7a243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_5556\\926444196.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data_stacked = torch.load('data/train_data_stacked.pt')\n"
     ]
    }
   ],
   "source": [
    "data_stacked = torch.load('data/train_data_stacked.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85be1ed7-22b0-4292-8f59-dbefba8429ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a403d31-1bd4-4e75-9788-31c7e99faee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_stacked = torch.load('data/train_set_for_model_structure.pt', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7582060f-e913-4281-8a41-e66bbc9dcff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stacked_test = torch.load('data/test_data_stacked.pt', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ee10396-3f4e-4b8f-b741-44ee6d5bf24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_stacked_dev = torch.load('data/dev_data_stacked.pt', weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a7650a1-b94b-4998-b58d-d47589f3ef22",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_stacked['X_train_stacked'][35000:40000]\n",
    "y_train = data_stacked['y_train_stacked'][35000:40000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a295e3-feaa-43d1-b0f0-3f1c7393dd85",
   "metadata": {},
   "source": [
    "## 라벨이 0인 값 제거(Autoencoder 학습용 정상 데이터만 추출)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b63d5ffd-0f97-45af-b277-1f736c496878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 1이 아닌 인덱스 찾기\n",
    "# indices = torch.nonzero(y_train != 1).squeeze()\n",
    "\n",
    "# # Boolean 마스크 생성\n",
    "# mask = torch.ones(y_train.size(0), dtype=torch.bool)\n",
    "# mask[indices] = False\n",
    "\n",
    "# # 마스크를 사용하여 X_train과 y_train 필터링\n",
    "# X_train = X_train[mask]\n",
    "# y_train = y_train[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52189634-0253-495d-b8a7-6257de211163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5000, 1, 36, 2048]), torch.Size([5000]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data_stacked['X_train_stacked'][35000:40000]\n",
    "y_train = data_stacked['y_train_stacked'][35000:40000]\n",
    "# X_train = data_stacked['X_train_stacked']\n",
    "# y_train = data_stacked['y_train_stacked']\n",
    "# X_train = data_stacked['X_train_for_model_structure']\n",
    "# y_train = data_stacked['y_train_for_model_structure']\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0827005e-2479-4e3d-aad3-d16eb7264e7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(410, 4590)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train[y_train == 0]), len(y_train[y_train != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "13d568a0-d004-41ee-8ed1-395fe0cfbcc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([37, 1, 36, 2048]), torch.Size([37]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = data_stacked_test['X_test_stacked']\n",
    "y_test = data_stacked_test['y_test_stacked']\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c0909b-2451-4417-995d-588ba842a9db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([37, 1, 36, 2048]), torch.Size([37]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_dev = data_stacked_dev['X_dev_stacked']\n",
    "y_dev = data_stacked_dev['y_dev_stacked']\n",
    "X_dev.shape, y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c22fc987-38f2-4609-bf0d-8d501dcaa6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pfns.PostProcessing('data/5528_droped_data.csv', 'cls') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "125cdf02-daad-43b5-a683-fb4305e89e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, y_train = data[0][0], data[0][1]\n",
    "# X_test, y_test = data[1][0], data[1][1]\n",
    "# X_dev, y_dev = data[2][0], data[2][1]\n",
    "# X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7b7d5b22-3f20-4813-80e0-50bda1d229e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train =  data[0][0].reshape(121, 12, 3, 2048)\n",
    "# X_train2 =  data[0][0].reshape(121, 36, 2048)\n",
    "\n",
    "# X_dev =  data[2][0].reshape(37, 12, 3, 2048)\n",
    "# X_dev2 =  data[2][0].reshape(37, 36, 2048)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10685495-ef63-4ce8-9322-4750d1bcd17b",
   "metadata": {},
   "source": [
    "## 모델 shape 바꿔서 넣어보기 (3차원, 2차원)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df33e401-f0bf-49bf-84ce-c82e3711510e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d29a90fc-0f8a-42df-830a-a07bc37de887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad454d66-6ff3-49f1-a2aa-ec28e433796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_stacked = X_train\n",
    "# X_train_stacked2 = X_train2\n",
    "# y_train_stacked = y_train_stacked2 = y_train\n",
    "\n",
    "# X_dev_stacked = X_dev\n",
    "# X_dev_stacked2 = X_dev2\n",
    "# y_dev_stacked = y_dev_stakced2 = y_dev\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b3cec-2d7b-48b2-9a59-a32a4b4a50fe",
   "metadata": {},
   "source": [
    "## 가중치 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a72ba081-e861-4b10-b842-2edb84059640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048]) torch.Size([2048]) torch.Size([2048]) torch.Size([3, 2048])\n"
     ]
    }
   ],
   "source": [
    "file_path='data/weight/5520_spectrum_x_weights.pkl'\n",
    "with open(file_path, 'rb') as f: \n",
    "    data = pickle.load(f)\n",
    "wf_x = torch.tensor(data)\n",
    "\n",
    "file_path='data/weight/5520_spectrum_y_weights.pkl'\n",
    "with open(file_path, 'rb') as f: \n",
    "    data = pickle.load(f)\n",
    "wf_y = torch.tensor(data)\n",
    "\n",
    "file_path='data/weight/5520_spectrum_z_weights.pkl'\n",
    "with open(file_path, 'rb') as f: \n",
    "    data = pickle.load(f)\n",
    "wf_z = torch.tensor(data)\n",
    "\n",
    "wf_xyz = torch.stack((wf_x, wf_y, wf_z))\n",
    "print(wf_x.shape, wf_y.shape, wf_z.shape, wf_xyz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8836a5-82c6-4032-97f0-cda662051f31",
   "metadata": {},
   "source": [
    "## 가중치 함수 브로드 캐스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "80693c59-175d-4347-aef1-9a01e136e443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_stacked = X_train * wf_xyz.reshape(1, 1, 3, 2048)\n",
    "# X_dev_stacked = X_dev_stacked * wf_xyz.reshape(1, 1, 3, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5aad18f1-d70e-4938-861a-d653c0679e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wf_broadcast = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48dd457-3de1-4aa8-ad5a-bdfa287bfa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stacked = X_train * wf_xyz.repeat(12, 1) * wf_broadcast\n",
    "X_dev_stacked = X_dev * wf_xyz.repeat(12, 1) * wf_broadcast\n",
    "X_test_stacked = X_test * wf_xyz.repeat(12, 1) * wf_broadcast\n",
    "# X_dev_stacked2 = X_dev_stacked2 * wf_xyz.repeat(12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "796a1e49-013e-4fc0-9075-043a9d5faa4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.lineplot(X_train_stacked[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "59697cae-b0a2-4b9e-b595-1b4a7b29e67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_stacked = X_train_stacked.to(torch.float32)\n",
    "# X_train_stacked2 = X_train_stacked2.to(torch.float32)\n",
    "# y_train_stacked = y_train_stacked.to(torch.float32)\n",
    "\n",
    "# X_dev_stacked = X_dev_stacked.to(torch.float32)\n",
    "# X_dev_stacked2 = X_dev_stacked2.to(torch.float32)\n",
    "# y_dev_stacked = y_dev_stacked.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7aec6db-01a1-4264-835d-7fe047fc6e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_stacked.shape, X_train_stacked2.shape, y_train_stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27402308-981f-4814-9876-fda781d2ab90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_stacked = y_train_stacked.reshape(121, 12)\n",
    "# y_dev_stacked = y_dev_stacked.reshape(37, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2129fa63-e8eb-4c64-a39b-023bb44afcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_stacked = torch.tensor([y_train_stacked[i][0].item() for i in range(y_train_stacked.shape[0])])\n",
    "# y_dev_stacked = torch.tensor([y_dev_stacked[i][0].item() for i in range(y_dev_stacked.shape[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80b50d9b-5f46-42cf-8dbb-b5a6f3db5053",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train_stacked, y_train)\n",
    "# train_dataset2 = TensorDataset(X_train_stacked2, y_train_stacked)\n",
    "# dev_dataset = TensorDataset(X_dev_stacked, y_dev_stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "895d1b66-f2a3-4aab-ae2f-e685a52a418b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = TensorDataset(X_test_stacked, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3875dd20-0746-4416-b070-2984282581a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_dataset = TensorDataset(X_dev_stacked, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3da8f56e-f95d-47b0-b655-8c13fb3736e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size , shuffle=True)\n",
    "# dataloader_train2 = DataLoader(train_dataset2, batch_size =batch_size , shuffle=True)\n",
    "# dataloader_dev = DataLoader(dev_dataset, batch_size =batch_size , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ffad773c-7ee0-495c-bb50-0b57038693b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_test = DataLoader(test_dataset, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "110b2c8a-c133-43e8-bd7b-ac485394340f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_dev = DataLoader(dev_dataset, batch_size=batch_size , shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed78f125-09d7-483b-bbf8-9d2907cb15cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([37, 1, 36, 2048])\n",
      "torch.Size([37, 1, 36, 2048])\n",
      "torch.Size([128, 1, 36, 2048])\n"
     ]
    }
   ],
   "source": [
    "for x_batch, labels in dataloader_dev:\n",
    "    print(x_batch.shape)\n",
    "    break\n",
    "for x_batch, labels in dataloader_test:\n",
    "    print(x_batch.shape)\n",
    "    break\n",
    "for x_batch, labels in dataloader:\n",
    "    print(x_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40867476-bbc0-4df7-9cb0-c27a4255ce58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# # 모델 정의\n",
    "# class BinaryClassifier(nn.Module):\n",
    "#     def __init__(self, input_size):\n",
    "#         super(BinaryClassifier, self).__init__()\n",
    "#         self.lstm = nn.LSTM(input_size=6144, hidden_size=128, num_layers=2, batch_first=True)\n",
    "#         self.fc = nn.Linear(128, 1)  # 이진 분류를 위한 출력 층\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # x: (batch_size, sequence_length, num_features, data_points)\n",
    "#         x = x.view(batch_size, 12, -1)  # (batch_size, sequence_length, num_features * data_points)\n",
    "#         lstm_out, _ = self.lstm(x)  # LSTM에 입력\n",
    "#         lstm_out = lstm_out[:, -1, :]  # 마지막 시퀀스의 출력 가져오기\n",
    "#         output = self.fc(lstm_out)  # 출력 층\n",
    "#         return torch.sigmoid(output)  # Sigmoid 활성화 함수\n",
    "\n",
    "# # 모델 인스턴스화 및 손실 함수, 옵티마이저 정의\n",
    "# model = BinaryClassifier(input_size=6144).to(device)  # input_size를 인자로 전달\n",
    "\n",
    "# criterion = nn.BCELoss()  # 이진 교차 엔트로피 손실\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# # 훈련 루프 구현\n",
    "# num_epochs = 20 # 훈련 epoch 수\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     for inputs, target in dataloader_train:\n",
    "#         inputs = inputs.to(device)\n",
    "#         target = target.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()  # 기울기 초기화\n",
    "#         outputs = model(inputs)  # 모델 예측\n",
    "#         loss = criterion(outputs, target.view(-1, 1))  # 손실 계산\n",
    "#         loss.backward()  # 기울기 계산\n",
    "#         optimizer.step()  # 가중치 업데이트\n",
    "\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eff4d656-2b64-4508-8151-f8ce14be335f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # 예측\n",
    "# model.eval()  # 모델을 평가 모드로 설정\n",
    "# predicted_labels = 0\n",
    "# # 예측 루프\n",
    "# with torch.no_grad():\n",
    "#     for inputs, _ in dataloader_dev:  # dataloader2에서 입력 데이터 가져오기\n",
    "#         inputs = inputs.to(device)  # 입력 데이터 CUDA로 이동\n",
    "        \n",
    "#         prediction = model(inputs)  # 모델 예측\n",
    "#         if (prediction > 0.5) :\n",
    "#             predicted_labels += 1 # 0.5 임계값을 기준으로 레이블 결정\n",
    "        \n",
    "#         # 예측된 레이블 출력\n",
    "#         print(f'Predicted label: {predicted_labels}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0890ded-c339-4148-9f55-b53366ad8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.001\n",
    "# num_epochs = 20\n",
    "\n",
    "# class ReshapeAndPermute(nn.Module):\n",
    "#     def forward(self, x):\n",
    "#         # x는 (배치사이즈, 1, 36, 2048) 형태로 들어옴\n",
    "#         x = x.view(-1, 36, 2048)  # (배치사이즈, 36, 2048)로 변환\n",
    "#         print(x.shape)\n",
    "#         # x = x.permute(0, 2, 1)  # (배치사이즈, 2048, 36)로 변환\n",
    "#         print(x.shape)\n",
    "#         return x\n",
    "\n",
    "# model = nn.Sequential(\n",
    "#             ReshapeAndPermute(),\n",
    "#             nn.Conv1d(in_channels=36, out_channels=16, kernel_size=1)  ,  # First Conv Layer\n",
    "#             nn.Conv1d(in_channels=16, out_channels=32, kernel_size=1) ,  # Second Conv Layer\n",
    "#             nn.Conv1d(in_channels=32, out_channels=64, kernel_size=1) ,\n",
    "#             nn.Conv2d(32, 64, kernel_size=(1, 4), stride=(1, 4), padding=0),  # Third Conv Layer\n",
    "#             nn.Flatten(),  # Flatten layer\n",
    "#             nn.Linear(64 * 2048, 128),  # Adjusted input size for Linear layer\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(128, 1)  # Dropout for regularization\n",
    "#         )\n",
    "\n",
    "# criterion = nn.BCEWithLogitsLoss() \n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b997f847-db7e-493b-a909-985b67559801",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# 레이블 준비 (0: negative, 1: positive라고 가정)\n",
    "y = np.array(dataloader_dev.dataset[0:37][1]) # 실제 레이블로 채워넣으세요\n",
    "\n",
    "# 클래스 가중치 계산\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "\n",
    "# BCEWithLogitsLoss에 사용할 pos_weight 계산\n",
    "pos_weight = torch.tensor([class_weights[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17947c64-59cf-463b-b3bd-1bb97b8e7b0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.16666667, 0.54411765])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2f17a4d9-efdb-4923-b0a5-3d76fe664d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1)),  # First Conv Layer\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2), \n",
    "    \n",
    "    nn.MaxPool2d(kernel_size=(1,2)),\n",
    "    \n",
    "    nn.Conv2d(8, 16, kernel_size=(3, 1), stride=(3, 1)),  # Second Conv Layer\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2),  # Dropout for regularization\n",
    "    \n",
    "    nn.MaxPool2d(kernel_size=(1,2)),\n",
    "    \n",
    "    nn.Conv2d(16, 8, kernel_size=(2, 2), stride=(2, 2)),  # Third Conv Layer\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Dropout(p=0.2),  # Dropout for regularization\n",
    "\n",
    "    nn.Conv2d(8, 1, kernel_size=(3, 1), stride=(3, 1)),  # Fourth Conv Layer\n",
    "    nn.ReLU(inplace=True),\n",
    "    \n",
    "    nn.Flatten(),\n",
    "    \n",
    "    nn.Linear(512, 256),  # Adjusted input size for Linear layer\n",
    "    nn.ReLU(inplace=True),\n",
    "               \n",
    "    nn.Linear(256, 64),  # Adjusted input size for Linear layer\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(64, 16),  # Second Linear layer\n",
    "    nn.ReLU(inplace=True),\n",
    "    nn.Linear(16, 1)  # Final output layer\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db93b3a7-a8ef-4cd1-9ac7-9f4eee0c8f1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight.to(device)) \n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b707d368-b305-402b-90bc-2339cbba5093",
   "metadata": {},
   "source": [
    "### Conv모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb1a99-dd4d-4aa5-b3ed-06ef1f32843b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988b1ee11bcb4302b4dedcdea8d2cf01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.3940\n",
      "Epoch [2/10], Loss: 0.3782\n",
      "Epoch [3/10], Loss: 0.2887\n",
      "Epoch [4/10], Loss: 0.2334\n",
      "Epoch [5/10], Loss: 0.2331\n",
      "Epoch [6/10], Loss: 0.2382\n",
      "Epoch [7/10], Loss: 0.2383\n",
      "Epoch [8/10], Loss: 0.2385\n"
     ]
    }
   ],
   "source": [
    "print(device)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for x_batch, labels in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x_batch = x_batch.to(device)  # Move x_batch to device\n",
    "        labels = labels.to(device).float()\n",
    "        labels = labels.unsqueeze(1)\n",
    "        \n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    avg_loss = running_loss / len(dataloader)\n",
    "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9de9295a-d6d2-471c-a346-212a646f0899",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataloader_dev.dataset[0:37][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535e0390-d024-45ca-a2bf-0f5413e97474",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.load('1003)stacked_model(0.68).pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a5ae7-5d80-468a-8f41-8429b8ca20d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataload = dataloader_dev\n",
    "\n",
    "model.eval()\n",
    "# Initialize variables to keep track of the loss and predictions\n",
    "total_loss = 0.0\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "correct_cnt = 0\n",
    "miss_cnt = 0\n",
    "label_zero = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x_batch, labels in dataload:  # Assuming you have a separate validation or test DataLoader\n",
    "        x_batch = x_batch.to(device)  # Move x_batch to device\n",
    "        labels = labels.to(device).float()  # Ensure labels are float for BCEWithLogitsLoss\n",
    "\n",
    "        outputs = model(x_batch)  # Forward pass\n",
    "        outputs = outputs.reshape(-1)\n",
    "        loss = criterion(outputs, labels)  # Calculate loss\n",
    "        total_loss += loss.item()  # Accumulate the loss\n",
    "\n",
    "        # Apply sigmoid to the outputs to get probabilities\n",
    "        print (outputs)\n",
    "        print(torch.sigmoid(outputs))\n",
    "        \n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        \n",
    "        all_labels.extend(labels.cpu().numpy())  # Store true labels\n",
    "        all_predictions.extend(predicted.cpu().numpy())  # Store predicted labels\n",
    "\n",
    "# Calculate average loss\n",
    "avg_loss = total_loss / len(dataload)  # Use the correct dataloader for length\n",
    "\n",
    "# Calculate precision, recall, and F1 score\n",
    "precision = precision_score(all_labels, all_predictions, average='weighted')  # Use 'micro' or 'macro' if needed\n",
    "recall = recall_score(all_labels, all_predictions, average='weighted')\n",
    "f1 = f1_score(all_labels, all_predictions, average='weighted')\n",
    "\n",
    "# Print results\n",
    "print(f\"Evaluation Loss: {avg_loss:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1 Score: {f1:.4f}\")\n",
    "all_labels = [label for label in all_labels]  # Extract first element from each array\n",
    "all_predictions = [pred for pred in all_predictions]  # Extract first element from each array\n",
    "\n",
    "for i in range(len(all_labels)):\n",
    "    if all_labels[i] == 0:  # all_labels의 값이 0인지 확인\n",
    "        label_zero += 1\n",
    "        if all_predictions[i] == 0:  # all_predictions의 값이 0인지 확인\n",
    "            correct_cnt += 1  # cnt를 증가시킴\n",
    "        else: miss_cnt += 1\n",
    "pred_zero_cnt = 0\n",
    "for i in range(len(all_predictions)):\n",
    "    if all_predictions[i] == 0:\n",
    "        pred_zero_cnt += 1\n",
    "\n",
    "print(all_labels)\n",
    "print(all_predictions)\n",
    "print(f\"correct : {correct_cnt}/{label_zero}\")\n",
    "print(f\"predicted zero : {pred_zero_cnt}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c338b244-c8cc-4604-b5db-ab8f70a775e4",
   "metadata": {},
   "source": [
    "### Autoencoder 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f33dfa89-2a8d-465e-8708-f446fe12c2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# class Autoencoder(nn.Module):\n",
    "#     def __init__(self, latent_dim):\n",
    "#         super(Autoencoder, self).__init__()\n",
    "#         self.latent_dim = latent_dim\n",
    "        \n",
    "#         # Encoder\n",
    "#         self.encoder = nn.Sequential(\n",
    "#             nn.Conv2d(1, 16, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.AdaptiveAvgPool2d((9, 256)),  # 크기를 고정\n",
    "#             nn.Flatten(),\n",
    "#             nn.Linear(64 * 9 * 256, latent_dim)\n",
    "#         )\n",
    "        \n",
    "#         # Decoder\n",
    "#         self.decoder = nn.Sequential(\n",
    "#             nn.Linear(latent_dim, 64 * 9 * 256),\n",
    "#             nn.Unflatten(1, (64, 9, 256)),\n",
    "#             nn.ConvTranspose2d(64, 32, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(32, 16, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.ConvTranspose2d(16, 1, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "#             nn.Upsample(size=(36, 2048), mode='bilinear', align_corners=False),\n",
    "#             nn.Sigmoid()\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         decoded = self.decoder(encoded)\n",
    "#         return decoded\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         encoded = self.encoder(x)\n",
    "#         decoded = self.decoder(encoded)\n",
    "#         return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc7b24bc-776c-4722-8123-161048f023c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.001\n",
    "# num_epochs = 10\n",
    "\n",
    "# last_dim = 512\n",
    "# model = Autoencoder(last_dim)\n",
    "# criterion = nn.MSELoss()  # 손실 함수\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)  # Adam 옵티마이저"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "84aebadc-e901-4ab8-a6ce-044b32f8c972",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# print(device)\n",
    "# model = model.to(device)\n",
    "# for epoch in tqdm(range(num_epochs)):\n",
    "#     model.train()  # 학습 모드\n",
    "#     running_loss = 0.0\n",
    "#     for x_batch,labels in dataloader:\n",
    "#         x_batch = x_batch.to(device)\n",
    "        \n",
    "#         optimizer.zero_grad()  # 기울기 초기화\n",
    "        \n",
    "#         outputs = model(x_batch)  # Autoencoder 출력\n",
    "        \n",
    "        \n",
    "#         loss = criterion(outputs, x_batch)  # 손실 계산\n",
    "        \n",
    "#         loss.backward()  # 기울기 계산\n",
    "#         optimizer.step()  # 파라미터 업데이트\n",
    "        \n",
    "#         running_loss += loss.item()\n",
    "    \n",
    "#     epoch_loss = running_loss / len(dataloader_dev)\n",
    "#     print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d3cf863e-eaac-407e-9006-f856487944e0",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# model.eval()\n",
    "# all_labels = []\n",
    "# all_predictions = []\n",
    "# all_errors = []\n",
    "\n",
    "# # MSE 손실 함수 인스턴스 생성\n",
    "# criterion = nn.MSELoss(reduction='none')\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for data, labels in tqdm(dataloader_dev):\n",
    "#         data = data.to(device)\n",
    "#         labels = labels.to(device)  # 레이블도 GPU로 이동\n",
    "        \n",
    "#         # Forward pass: input to autoencoder\n",
    "#         reconstructed = model(data)\n",
    "        \n",
    "#         # Compute reconstruction error (MSE)\n",
    "#         reconstruction_error = criterion(reconstructed, data)  # 손실 계산\n",
    "#         reconstruction_error = reconstruction_error.mean(dim=[1, 2, 3])  # Averaging over all dimensions\n",
    "#                 # Store the actual labels and reconstruction errors\n",
    "#         all_labels.append(labels)\n",
    "#         all_errors.append(reconstruction_error)\n",
    "\n",
    "# # concatenate results and move to CPU\n",
    "# all_labels = torch.cat(all_labels).cpu().numpy()\n",
    "# all_errors = torch.cat(all_errors).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f7a94b17-48f9-4aac-9ade-71215901b86d",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# # Binary classification: if error > threshold -> anomaly (1), else normal (0)\n",
    "# threshold = 0.3  # 적절한 threshold 값을 설정해야 합니다\n",
    "# all_predictions = (all_errors > threshold).astype(int)\n",
    "\n",
    "# # Evaluation metrics\n",
    "# print(classification_report(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "454b051b-1a85-4c05-b029-f36ebcccaeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'model_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "34387b73-4211-419d-a647-de47842b364f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_9280\\480446460.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load('1003)stacked_model(0.68).pth')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "  (1): ReLU(inplace=True)\n",
       "  (2): Dropout(p=0.5, inplace=False)\n",
       "  (3): Conv2d(8, 16, kernel_size=(3, 1), stride=(3, 1))\n",
       "  (4): ReLU(inplace=True)\n",
       "  (5): Dropout(p=0.5, inplace=False)\n",
       "  (6): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (7): ReLU(inplace=True)\n",
       "  (8): Dropout(p=0.5, inplace=False)\n",
       "  (9): Conv2d(32, 16, kernel_size=(3, 1), stride=(3, 1))\n",
       "  (10): ReLU(inplace=True)\n",
       "  (11): Conv2d(16, 8, kernel_size=(2, 1), stride=(2, 1))\n",
       "  (12): ReLU(inplace=True)\n",
       "  (13): Conv2d(8, 1, kernel_size=(1, 2), stride=(1, 2))\n",
       "  (14): ReLU(inplace=True)\n",
       "  (15): Dropout(p=0.4, inplace=False)\n",
       "  (16): Flatten(start_dim=1, end_dim=-1)\n",
       "  (17): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (18): ReLU(inplace=True)\n",
       "  (19): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (20): ReLU(inplace=True)\n",
       "  (21): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (22): ReLU(inplace=True)\n",
       "  (23): Linear(in_features=16, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('1003)stacked_model(0.68).pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61db3af8-cf10-4d3a-9406-836332e5b3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
