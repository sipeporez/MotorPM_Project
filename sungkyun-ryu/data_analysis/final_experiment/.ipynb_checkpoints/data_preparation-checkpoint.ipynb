{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ddcf441-ae45-4e36-a3ff-bc484478a44e",
   "metadata": {},
   "source": [
    "## Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39537e03-7b43-4d1b-8992-6e6bf166543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdm_functions as fns\n",
    "import torch \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4c005a8-b04f-4b65-8edb-68ef6bd4be31",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_normal = pd.read_csv('../dataset/5528_drop_imbalance_normal.csv')\n",
    "f_error = pd.read_csv('../dataset/5528_drop_imbalance_error.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1a516a8b-82fb-4d77-9e4b-80c5684617d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_normal['created_at'] = pd.to_datetime(f_normal['created_at'], unit='s')\n",
    "f_normal = f_normal.sort_values(by='created_at')\n",
    " \n",
    "f_error['created_at'] = pd.to_datetime(f_error['created_at'], unit='s')\n",
    "f_error = f_error.sort_values(by='created_at')\n",
    "\n",
    "f_normal = f_normal.drop(columns=['asset_id', 'created_at', 'created_at_datetime', 'looseness_health', 'time','misalignment_health', 'bearing_health', 'imbalance_health'])\n",
    "f_error = f_error.drop(columns=['asset_id', 'created_at', 'created_at_datetime', 'looseness_health', 'time','misalignment_health', 'bearing_health', 'imbalance_health'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e3ffe5b-28a2-431b-997f-3f3f51c293f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2220, 38]), torch.Size([192, 38]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_normal_tensor = torch.tensor(f_normal.values, dtype=torch.float32)\n",
    "f_error_tensor = torch.tensor(f_error.values, dtype=torch.float32)\n",
    "\n",
    "f_normal_tensor.shape, f_error_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbe7fde9-5a27-450a-a11c-3604c9c248c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1020, 38]), torch.Size([1200, 38]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_normal_test = f_normal_tensor[:1200]\n",
    "f_normal_train = f_normal_tensor[1200:]\n",
    "\n",
    "f_normal_train.shape, f_normal_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a9fd58d-9c95-453b-b664-8b91124b26ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_normal_label = torch.ones((1200))\n",
    "f_error_label = torch.zeros((192))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89d8c249-f1ac-45b1-b64d-fc8d3dceaab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1200])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_normal_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf0006ae-fee5-4a17-8979-4fd77361cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_test = torch.concat((f_normal_test, f_error_tensor), dim = 0) \n",
    "f_test_label = torch.concat((f_normal_label, f_error_label), dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1735cd54-e097-4737-b555-d51043cb2575",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1392, 38]), torch.Size([1392]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_test.shape, f_test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dea70d05-0249-4306-96e2-2835e5bc2632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f_test_label[f_test_label != 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "23b71003-d55f-4412-881b-1a54113030cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1020, 38])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_normal_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b80883b-d75d-4429-afc5-b2c4851fb037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 13/13 [00:00<00:00, 406.28it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1105, 1, 12, 38])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_normal_train = f_normal_train.reshape((-1, 1, 12, 38))\n",
    "f_normal_train = fns.multi_datasets_stacks(f_normal_train, multi_dim = 13, num_groups = 12 )\n",
    "f_normal_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57cdd1aa-fc0e-4e20-aeeb-505fcdb3a55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13260, 38])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_normal_train = f_normal_train.reshape(-1, 38)\n",
    "f_normal_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a9c1843e-9e25-4004-a7d5-37489f4a03e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'train' : f_normal_train, 'test' : f_test, 'test_label': f_test_label}, 'datasets/auto_encoder_supervised.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4571470-d7db-46b0-a094-9172d1d77d0e",
   "metadata": {},
   "source": [
    "## <span style='color:white'> ================================================================================================================================================================= </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635989fd-cd74-4cbd-ae61-9484e01d877b",
   "metadata": {},
   "source": [
    "## Model Running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1f29ab8-dd12-4b6b-bef8-d9f7d6161d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4d472c7-00ad-402b-8df2-e1a5563ea0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_14480\\2151635847.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  data = torch.load('datasets/auto_encoder_supervised.pt')\n"
     ]
    }
   ],
   "source": [
    "data = torch.load('datasets/auto_encoder_supervised.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5e739840-383f-4364-9372-b9895374f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data['train']\n",
    "test_data =data['test']\n",
    "test_label = data['test_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47fbef96-baf5-4e0b-92d1-14f3c6ab188a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "train_data = scaler.fit_transform(train_data)\n",
    "test_data = scaler.fit_transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "08d76242-b3bd-4772-a5d1-101ba961e19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor(train_data, dtype = torch.float32)\n",
    "test_data = torch.tensor(test_data, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "57bd94e9-074a-410f-817c-b047666eccd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class AnomalyDetector(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AnomalyDetector, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(38, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 2),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(2, 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(4, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 38),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Initialize model\n",
    "autoencoder = AnomalyDetector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "75b28667-a9c6-4289-b424-b9effb5fd99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.L1Loss()  # MAE in PyTorch\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7d576993-5955-40e8-9ed0-7d0bbba25f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset = TensorDataset(train_data)\n",
    "test_dataset = TensorDataset(test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ebfd2a2f-a21e-493a-93a8-24b78bbd4443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader_train = DataLoader(train_dataset, batch_size = 512, shuffle = True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size = 512, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0f15708d-66da-4882-a4ba-0313e3f576d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 0.31725832246817076\n",
      "Epoch [2/20], Loss: 0.31728509297737706\n",
      "Epoch [3/20], Loss: 0.3172836578809298\n",
      "Epoch [4/20], Loss: 0.31725933803961825\n",
      "Epoch [5/20], Loss: 0.3172763150471907\n",
      "Epoch [6/20], Loss: 0.3172508397927651\n",
      "Epoch [7/20], Loss: 0.31729149245298827\n",
      "Epoch [8/20], Loss: 0.3172851949930191\n",
      "Epoch [9/20], Loss: 0.3172650704017052\n",
      "Epoch [10/20], Loss: 0.31728053322205174\n",
      "Epoch [11/20], Loss: 0.31727377611857194\n",
      "Epoch [12/20], Loss: 0.317266576565229\n",
      "Epoch [13/20], Loss: 0.3172551015248665\n",
      "Epoch [14/20], Loss: 0.31726726774985975\n",
      "Epoch [15/20], Loss: 0.3172501279757573\n",
      "Epoch [16/20], Loss: 0.3172668573948053\n",
      "Epoch [17/20], Loss: 0.31728356503523314\n",
      "Epoch [18/20], Loss: 0.31728410376952243\n",
      "Epoch [19/20], Loss: 0.3172891277533311\n",
      "Epoch [20/20], Loss: 0.3172932817385747\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    autoencoder.train()\n",
    "    running_loss = 0.0\n",
    "    for x_batch in dataloader_train:\n",
    "        # inputs = x_batch\n",
    "        outputs = autoencoder(x_batch[0])\n",
    "        loss = criterion(outputs, x_batch[0])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(dataloader_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c22145f4-4edd-498d-b702-27d983e82731",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ab59c22b-1a30-42ac-b535-b9bd6fc042ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.3377, Accuracy: 0.6509,\n"
     ]
    }
   ],
   "source": [
    "autoencoder.eval()  # Set the model to evaluation mode\n",
    "total_loss = 0.0\n",
    "# correct = 0\n",
    "# error_correct = 0\n",
    "# total = 0\n",
    "threshold = 0.1\n",
    "\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "\n",
    "with torch.no_grad():  # No gradients needed for evaluation\n",
    "    for x_batch, labels in dataloader_test:  # Assuming labels are included in your test loader\n",
    "        # print(x_batch.shape)\n",
    "        outputs = autoencoder(x_batch)\n",
    "        loss = criterion(outputs, x_batch)  # Calculate reconstruction loss\n",
    "        total_loss += loss.item()\n",
    "        # Calculate reconstruction error\n",
    "        reconstruction_error = torch.mean((outputs - x_batch) ** 2, dim = 1 )\n",
    "        # print(reconstruction_error)\n",
    "        # Identify anomalies based on the threshold\n",
    "        predictions = (reconstruction_error > threshold).float()        \n",
    "\n",
    "        # Compare predictions with actual labels\n",
    "        # error_mask = (labels == 0)\n",
    "        # error_correct += ((predictions[error_mask] == 0).sum()).item()  \n",
    "        # correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        all_labels.extend(labels.cpu().numpy())  # Move to CPU and convert to numpy\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "\n",
    "# Calculate average loss and accuracy\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "average_loss = total_loss / len(dataloader_test)\n",
    "accuracy = correct / total\n",
    "\n",
    "print(f\"Test Loss: {average_loss:.4f}, Accuracy: {accuracy:.4f},\")\n",
    "print(conf_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "580bda12-8588-4f4d-a79c-c7117a335112",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebfbb4d-213c-46c2-a438-e1e2f6d1132d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
